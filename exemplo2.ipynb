{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c3d54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MASTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\MASTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MASTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\MASTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m line = f_neg.readline()\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(line) > \u001b[32m0\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     classification = \u001b[43mlexico\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassic_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     tot_neg += \u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tot_neg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\Site\\lexico.py:129\u001b[39m, in \u001b[36mLexico.classic_classification\u001b[39m\u001b[34m(self, text, text_file, x_print)\u001b[39m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m.tokens)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Remove Stop Word\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mremove_stopword\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(x_print):\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStopwords Removed:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\Site\\lexico.py:104\u001b[39m, in \u001b[36mLexico.remove_stopword\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremove_stopword\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# Remove tokens that dont help in classification (words with specific tags can be taken out)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     rmv_sw = \u001b[43mStopword_RMV\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m.tokens = rmv_sw.remove_stopwords(\u001b[38;5;28mself\u001b[39m.tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\Site\\Modules\\stopword.py:14\u001b[39m, in \u001b[36mStopword_RMV.__init__\u001b[39m\u001b[34m(self, pt)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pt = \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m(pt):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28mself\u001b[39m.stop_words = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msw_pt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     16\u001b[39m         \u001b[38;5;28mself\u001b[39m.stop_words = \u001b[38;5;28mself\u001b[39m.sw_en()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\Site\\Modules\\stopword.py:40\u001b[39m, in \u001b[36mStopword_RMV.sw_pt\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msw_pt\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# loading pt_lang small model in spacy package (size = 416)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     pt = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpt_core_news_sm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m#pt = spacy.load('pt_core_news_lg')\u001b[39;00m\n\u001b[32m     42\u001b[39m     spacy_pt = pt.Defaults.stop_words\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     28\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     29\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     35\u001b[39m ) -> Language:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\util.py:465\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name.replace(\u001b[33m\"\u001b[39m\u001b[33mblank:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))()\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Path(name).exists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), **kwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\util.py:501\u001b[39m, in \u001b[36mload_model_from_package\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[32m    485\u001b[39m \n\u001b[32m    486\u001b[39m \u001b[33;03mname (str): The package name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m \u001b[33;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[38;5;28mcls\u001b[39m = importlib.import_module(name)\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\pt_core_news_sm\\__init__.py:10\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(**overrides)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(**overrides):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\util.py:682\u001b[39m, in \u001b[36mload_model_from_init_py\u001b[39m\u001b[34m(init_file, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path.exists():\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E052.format(path=data_path))\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\util.py:547\u001b[39m, in \u001b[36mload_model_from_path\u001b[39m\u001b[34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    538\u001b[39m config = load_config(config_path, overrides=overrides)\n\u001b[32m    539\u001b[39m nlp = load_model_from_config(\n\u001b[32m    540\u001b[39m     config,\n\u001b[32m    541\u001b[39m     vocab=vocab,\n\u001b[32m   (...)\u001b[39m\u001b[32m    545\u001b[39m     meta=meta,\n\u001b[32m    546\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\language.py:2246\u001b[39m, in \u001b[36mLanguage.from_disk\u001b[39m\u001b[34m(self, path, exclude, overrides)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path / \u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m).exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m   2244\u001b[39m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[32m   2245\u001b[39m     exclude = \u001b[38;5;28mlist\u001b[39m(exclude) + [\u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2246\u001b[39m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserializers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   2247\u001b[39m \u001b[38;5;28mself\u001b[39m._path = path  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   2248\u001b[39m \u001b[38;5;28mself\u001b[39m._link_components()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\util.py:1390\u001b[39m, in \u001b[36mfrom_disk\u001b[39m\u001b[34m(path, readers, exclude)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers.items():\n\u001b[32m   1388\u001b[39m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\language.py:2240\u001b[39m, in \u001b[36mLanguage.from_disk.<locals>.<lambda>\u001b[39m\u001b[34m(p, proc)\u001b[39m\n\u001b[32m   2238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mfrom_disk\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2239\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     deserializers[name] = \u001b[38;5;28;01mlambda\u001b[39;00m p, proc=proc: \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[misc]\u001b[39;49;00m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvocab\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path / \u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m).exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m   2244\u001b[39m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[32m   2245\u001b[39m     exclude = \u001b[38;5;28mlist\u001b[39m(exclude) + [\u001b[33m\"\u001b[39m\u001b[33mvocab\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:343\u001b[39m, in \u001b[36mspacy.pipeline.trainable_pipe.TrainablePipe.from_disk\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\util.py:1390\u001b[39m, in \u001b[36mfrom_disk\u001b[39m\u001b[34m(path, readers, exclude)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers.items():\n\u001b[32m   1388\u001b[39m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:340\u001b[39m, in \u001b[36mspacy.pipeline.trainable_pipe.TrainablePipe.from_disk.lambda8\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\codigos HD\\PLN\\myenv\\Lib\\site-packages\\spacy\\pipeline\\pipe.pyx:148\u001b[39m, in \u001b[36mspacy.pipeline.pipe.deserialize_config\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib.py:1235\u001b[39m, in \u001b[36mPath.exists\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1231\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[33;03mWhether this path exists.\u001b[39;00m\n\u001b[32m   1233\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1237\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _ignore_error(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\pathlib.py:1013\u001b[39m, in \u001b[36mPath.stat\u001b[39m\u001b[34m(self, follow_symlinks)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstat\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, follow_symlinks=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1009\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[33;03m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[33;03m    os.stat() does.\u001b[39;00m\n\u001b[32m   1012\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m os.stat(\u001b[38;5;28mself\u001b[39m, follow_symlinks=follow_symlinks)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from Site.lexico import Lexico\n",
    "from Site.Modules.utils import progressBar\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "lexico = Lexico(\"LIWC.txt\")\n",
    "\n",
    "#resposta = lexico.classic_classification(\"Matou uma criança\")\n",
    "#print(resposta)\n",
    "\n",
    "f_neg = open(\"books_pt_neg\", \"r\", encoding=\"utf-8\")\n",
    "f_pos = open(\"books_pt_pos\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "#print(df)\n",
    "\n",
    "neg = 0\n",
    "pos = 0\n",
    "\n",
    "tot_neg = 0\n",
    "tot_pos = 0\n",
    "\n",
    "line = f_neg.readline()\n",
    "while(len(line) > 0):\n",
    "    classification = lexico.classic_classification(line)\n",
    "\n",
    "    tot_neg += 1\n",
    "    print(tot_neg)\n",
    "\n",
    "    #print(classification)\n",
    "\n",
    "    if(classification == \"Negativo\"):\n",
    "        neg +=1\n",
    "\n",
    "    line = f_neg.readline()\n",
    "\n",
    "\n",
    "line = f_pos.readline()\n",
    "while(len(line) > 0):\n",
    "    classification = lexico.classic_classification(line)\n",
    "\n",
    "    tot_pos += 1\n",
    "    print(tot_pos)\n",
    "\n",
    "    #print(classification)\n",
    "\n",
    "    if(classification == \"Positivo\"):\n",
    "        pos +=1\n",
    "\n",
    "    line = f_pos.readline()\n",
    "\n",
    "print(neg / tot_neg)\n",
    "print(pos / tot_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
